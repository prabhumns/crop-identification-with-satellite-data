{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import os\n",
    "from sklearn import svm, tree\n",
    "from statistics import mean\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle as shf\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "data2 = {}\n",
    "print('loading data')\n",
    "for key in os.listdir('E:/Time Series/hdf_files2'):\n",
    "\tfilename = 'E:/Time Series/hdf_files2/'+ key\n",
    "\tf = h5py.File(filename, 'r')\n",
    "\tdata2[key] = list(list(f.values())[0])\n",
    "\tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALFALFA --- 20000\n",
      "CORN --- 20000\n",
      "DEVELOPED --- 20000\n",
      "SOYABEENS --- 20000\n",
      "WATER_BODY --- 20000\n"
     ]
    }
   ],
   "source": [
    "for key, value in data2.items():\n",
    "    print(key, '---', len(value))\n",
    "    shuffle(data2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'DEVELOPED':data2['DEVELOPED'][:19500], 'ALFALFA':data2['ALFALFA'][:2000], 'CORN': data2['CORN'][:5000], 'SOYABEENS':data2['SOYABEENS'][:500], 'WATERBODY':data2['WATER_BODY'][:3000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = {'DEVELOPED':data2['DEVELOPED'][19500:], 'ALFALFA':data2['ALFALFA'][19500:], 'CORN': data2['CORN'][19500:], 'SOYABEENS':data2['SOYABEENS'][19900:], 'WATERBODY':data2['WATER_BODY'][19500:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {key:value[:19000] for key, value in data2.items() if len(value) >= 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = {}; maxs = {}; means = {}\n",
    "for i in range(45):\n",
    "    lin = [l[i] for value in data.values() for l in value]\n",
    "    mins[i] = min(lin)\n",
    "    maxs[i] = max(lin)\n",
    "    means[i] = mean(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in ushort_scalars\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = {key: [[np.float64((example[i]-means[i])/(maxs[i] - mins[i])) for i in range(45)] for example in value] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys():\n",
    "    shuffle(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : DEVELOPED\n",
      "1 : ALFALFA\n",
      "2 : CORN\n",
      "3 : SOYABEENS\n",
      "4 : WATERBODY\n"
     ]
    }
   ],
   "source": [
    "training_examples = []\n",
    "training_labels = []\n",
    "i = 0;\n",
    "for key, value in data.items():\n",
    "    training_examples = training_examples + value\n",
    "    training_labels = training_labels + [i for v in range(len(value))]\n",
    "    print(i,':', key)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples, training_labels  = shf(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = {key:value[19000:] for key, value in data2.items() if len(value) >= 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in ushort_scalars\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_cv = {key: [[np.float64((example[i]-means[i])/(maxs[i] - mins[i])) for i in range(45)] for example in value] for key, value in data_cv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : DEVELOPED\n",
      "1 : ALFALFA\n",
      "2 : CORN\n",
      "3 : SOYABEENS\n",
      "4 : WATERBODY\n"
     ]
    }
   ],
   "source": [
    "cv_examples = []\n",
    "cv_labels = []\n",
    "i = 0;\n",
    "for key, value in data_cv.items():\n",
    "    cv_examples = cv_examples + value\n",
    "    cv_labels = cv_labels + [i for v in range(len(value))]\n",
    "    print(i,':', key)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:605: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:610: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7485333333333334\n",
      "0.974 DEVELOPED\n",
      "0.06 ALFALFA\n",
      "0.304 CORN\n",
      "0.0 SOYABEENS\n",
      "0.562 WATERBODY\n",
      "0.4523809523809524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "be = SVC(C=1.0, \n",
    "         cache_size=200, \n",
    "         class_weight=None, \n",
    "         coef0=0.0,\n",
    "         decision_function_shape='ovr', \n",
    "         degree=3, \n",
    "         gamma='auto',\n",
    "         kernel='rbf',\n",
    "         max_iter=-1, \n",
    "         probability=False, \n",
    "         random_state=None, \n",
    "         shrinking=True, \n",
    "         tol=0.001, \n",
    "         verbose=False)\n",
    "crf = BaggingClassifier(base_estimator=be,\n",
    "                        n_estimators=10,\n",
    "                        max_samples=0.,\n",
    "                        max_features = 0.5,\n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        oob_score=True,\n",
    "                        warm_start=False,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=None,\n",
    "                        verbose=0)\n",
    "crf = crf.fit(training_examples, training_labels)\n",
    "print(sum(crf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "i = 0\n",
    "cv_predictions = []\n",
    "for key, value in data_cv.items():\n",
    "    t = crf.predict(value)\n",
    "    print(sum(t==[i for t in value])/len(value), key)\n",
    "    cv_predictions = cv_predictions + list(t)\n",
    "    i = i+1\n",
    "print(sum(np.array(cv_predictions) == cv_labels)/len(cv_labels))\n",
    "crf.base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7636\n",
      "0.956 DEVELOPED\n",
      "0.228 ALFALFA\n",
      "0.328 CORN\n",
      "0.0 SOYABEENS\n",
      "0.596 WATERBODY\n",
      "0.5019047619047619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "be = SVC(C=1.0, \n",
    "         cache_size=200, \n",
    "         class_weight=None, \n",
    "         coef0=0.0,\n",
    "         decision_function_shape='ovr', \n",
    "         degree=3, \n",
    "         gamma='auto',\n",
    "         kernel='rbf',\n",
    "         max_iter=-1, \n",
    "         probability=True, \n",
    "         random_state=None, \n",
    "         shrinking=True, \n",
    "         tol=0.001, \n",
    "         verbose=False)\n",
    "crf = BaggingClassifier(base_estimator=be,\n",
    "                        n_estimators=10,\n",
    "                        max_samples=0.3,\n",
    "                        max_features = 0.5,\n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False,\n",
    "                        oob_score=True,\n",
    "                        warm_start=False,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=None,\n",
    "                        verbose=0)\n",
    "crf = crf.fit(training_examples, training_labels)\n",
    "print(sum(crf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "i = 0\n",
    "cv_predictions = []\n",
    "for key, value in data_cv.items():\n",
    "    t = crf.predict(value)\n",
    "    print(sum(t==[i for t in value])/len(value), key)\n",
    "    cv_predictions = cv_predictions + list(t)\n",
    "    i = i+1\n",
    "print(sum(np.array(cv_predictions) == cv_labels)/len(cv_labels))\n",
    "crf.base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.973825"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=100000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.0000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "sum(clf.predict(training_examples) == training_labels)/len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_object = open('9_pixels_learning_2.pkl', 'wb')\n",
    "pickle.dump([mins, maxs, means, clf], file_object)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9919666666666667\n",
      "0.964 DEVELOPED\n",
      "0.454 ALFALFA\n",
      "0.742 CORN\n",
      "0.24 SOYABEENS\n",
      "0.76 WATERBODY\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "crf = RandomForestClassifier(n_estimators=10, \n",
    "                             criterion='gini', \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='auto', \n",
    "                             max_leaf_nodes=None, \n",
    "                             min_impurity_decrease=0.0, \n",
    "                             min_impurity_split=None, \n",
    "                             bootstrap=True, \n",
    "                             oob_score=False, \n",
    "                             n_jobs=1, \n",
    "                             random_state=None, \n",
    "                             verbose=0, \n",
    "                             warm_start=False, \n",
    "                             class_weight=None)\n",
    "crf = crf.fit(training_examples, training_labels)\n",
    "print(sum(crf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "i = 0\n",
    "for key, value in data_cv.items():\n",
    "    print(sum(crf.predict(value)==[i for t in value])/len(value), key)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9902\n",
      "0.958 DEVELOPED\n",
      "0.426 ALFALFA\n",
      "0.74 CORN\n",
      "0.21 SOYABEENS\n",
      "0.764 WATERBODY\n",
      "0.6976190476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "crf = RandomForestClassifier(n_estimators=10, \n",
    "                             criterion='gini', \n",
    "                             max_depth=30, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='auto', \n",
    "                             max_leaf_nodes=None, \n",
    "                             min_impurity_decrease=0.0, \n",
    "                             min_impurity_split=None, \n",
    "                             bootstrap=True, \n",
    "                             oob_score=False, \n",
    "                             n_jobs=1, \n",
    "                             random_state=None, \n",
    "                             verbose=0, \n",
    "                             warm_start=False, \n",
    "                             class_weight={0:1/19500, 1: 1/2000, 2:1/5000 ,3:1/500 ,4:1/3000})\n",
    "crf = crf.fit(training_examples, training_labels)\n",
    "print(sum(crf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "i = 0\n",
    "cv_predictions = []\n",
    "for key, value in data_cv.items():\n",
    "    t = crf.predict(value)\n",
    "    print(sum(t==[i for t in value])/len(value), key)\n",
    "    cv_predictions = cv_predictions + list(t)\n",
    "    i = i+1\n",
    "print(sum(np.array(cv_predictions) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-37-4ac2fa5a07c2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-4ac2fa5a07c2>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    crf = ExtraTreeClassifier(criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None)\u001b[0m\n\u001b[1;37m                                                                                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "crf = ExtraTreeClassifier(criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None)\n",
    "crf = crf.fit(training_examples, training_labels)\n",
    "print(sum(crf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "i = 0\n",
    "cv_predictions = []\n",
    "for key, value in data_cv.items():\n",
    "    t = crf.predict(value)\n",
    "    print(sum(t==[i for t in value])/len(value), key)\n",
    "    cv_predictions = cv_predictions + list(t)\n",
    "    i = i+1\n",
    "print(sum(np.array(cv_predictions) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7676\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree2.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier()\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598\n",
      "0.6069157894736842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import graphviz \\ndot_data = tree.export_graphviz(ctf, out_file=None) \\ngraph = graphviz.Source(dot_data) \\ngraph.render(\"decisiontree2\") '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "'''import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree2\") '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6362\n",
      "0.6449263157894737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree4.pdf'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695\n",
      "0.695178947368421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree5.pdf'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7138\n",
      "0.7228105263157895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree6.pdf'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 6)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398\n",
      "0.7406947368421053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree7.pdf'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 7)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7474\n",
      "0.7565052631578948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree8.pdf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 8)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7772\n",
      "0.814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decisiontree11.pdf'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf = tree.DecisionTreeClassifier(max_depth = 11)\n",
    "ctf = ctf.fit(training_examples, training_labels)\n",
    "print(sum(ctf.predict(cv_examples)==cv_labels)/len(cv_labels))\n",
    "print(sum(ctf.predict(training_examples)==training_labels)/len(training_labels))\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(ctf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decisiontree11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.969625\n",
      "0.77355\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 30000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.0000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.964525\n",
      "0.7797\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 10000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : CORN\n",
      "1 : DEVELOPED\n",
      "2 : SOYABEENS\n",
      "3 : WATER_BODY\n"
     ]
    }
   ],
   "source": [
    "cv_examples = []\n",
    "cv_labels = []\n",
    "i = 0;\n",
    "for key, value in data_cv.items():\n",
    "    training_examples = training_examples + value[:4000]\n",
    "    training_labels = training_labels + [i for v in range(4000)]\n",
    "    cv_examples = cv_examples + value[4000:]\n",
    "    cv_labels = cv_labels + [i for v in range(1000)]\n",
    "    print(i,':', key)\n",
    "    i+=1\n",
    "training_examples, training_labels = shf(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9539821428571429\n",
      "0.79575\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.00001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9539821428571429\n",
      "0.79575\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.00001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9438392857142858\n",
      "0.80225\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 1000,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8666785714285714\n",
      "0.7925\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 1,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8903571428571428\n",
      "0.796\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9015357142857143\n",
      "0.79925\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 10,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9110357142857143\n",
      "0.80475\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 30,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.0000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9215\n",
      "0.8085\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 100,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.0000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9262321428571428\n",
      "0.80975\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 170,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.01, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8666607142857143\n",
      "0.79275\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 1,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.01, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.9264210526315789\n",
      "0.80775\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 170,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.01, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8846842105263157\n",
      "0.793\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 2,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8905921052631579\n",
      "0.79175\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3,\n",
    "              kernel='rbf', \n",
    "              degree= 3,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.22557894736842105\n",
      "0.22425\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3,\n",
    "              kernel='sigmoid', \n",
    "              degree= 2,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "print (sum(clf.predict(training_examples) == training_labels)/len(training_labels))\n",
    "print(sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8432315789473684"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C= 3,\n",
    "              kernel='rbf', \n",
    "              degree= 2,\n",
    "              gamma= 'auto',\n",
    "              coef0=0.0,\n",
    "              shrinking=True, \n",
    "              probability= False, \n",
    "              tol=0.000001, \n",
    "              cache_size=200, \n",
    "              class_weight=None, \n",
    "              verbose=True, \n",
    "              max_iter=-1, \n",
    "              decision_function_shape='ovr', \n",
    "              random_state=None)\n",
    "clf.fit(training_examples, training_labels)\n",
    "sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels)\n",
    "sum(clf.predict(training_examples) == training_labels)/len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ----- 0.0629666574050501\n",
      "29 ----- 0.042415007033263896\n",
      "9 ----- 0.04175524834329842\n",
      "38 ----- 0.04035329115930774\n",
      "13 ----- 0.030888461304013903\n",
      "19 ----- 0.030191824894230872\n",
      "14 ----- 0.029834342793438363\n",
      "10 ----- 0.0288195506991518\n",
      "0 ----- 0.02864051036691719\n",
      "34 ----- 0.02692124937730108\n",
      "18 ----- 0.02646967599997988\n",
      "1 ----- 0.025950561874806842\n",
      "8 ----- 0.024935955823798338\n",
      "4 ----- 0.023591169984353032\n",
      "43 ----- 0.022740660178468697\n",
      "11 ----- 0.02206169851263916\n",
      "23 ----- 0.021553974804947487\n",
      "41 ----- 0.02113211872347874\n",
      "26 ----- 0.02079389961651347\n",
      "33 ----- 0.019670888829301285\n",
      "37 ----- 0.019628781424271935\n",
      "39 ----- 0.019118838662844466\n",
      "28 ----- 0.01879564109780771\n",
      "15 ----- 0.018755689470142032\n",
      "7 ----- 0.018694204772217074\n",
      "36 ----- 0.018208041329346347\n",
      "32 ----- 0.01788341135447162\n",
      "5 ----- 0.017631936986604858\n",
      "30 ----- 0.017291377692063147\n",
      "25 ----- 0.016395993392518276\n",
      "24 ----- 0.01604944109013577\n",
      "2 ----- 0.01602912643977806\n",
      "20 ----- 0.01599004957051735\n",
      "42 ----- 0.015989098124278456\n",
      "16 ----- 0.01591037352652206\n",
      "3 ----- 0.015616288308641837\n",
      "31 ----- 0.015572747055865584\n",
      "12 ----- 0.015525233685748208\n",
      "40 ----- 0.01541942617541785\n",
      "6 ----- 0.015331559243319115\n",
      "27 ----- 0.014796949569979578\n",
      "17 ----- 0.013803652067397126\n",
      "22 ----- 0.013564741689843538\n",
      "35 ----- 0.013204108382362837\n",
      "21 ----- 0.01310654116364487\n",
      "[44, 29, 9, 38, 13, 19, 14, 10, 0, 34, 18, 1, 8, 4, 43, 11, 23, 41, 26]\n"
     ]
    }
   ],
   "source": [
    "s = model.feature_importances_\n",
    "L = np.array(s)\n",
    "t = sorted(range(len(L)), key=lambda i:L[i])\n",
    "z = []; r = 0\n",
    "for j in t[::-1]:\n",
    "    print( j, '-----', s[j])\n",
    "    if s[j]>0.02:\n",
    "        z.append(j)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = [[example[t] for t in z] for example in training_examples ]\n",
    "cv_examples = [[example[t] for t in z]for example in cv_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = MLPClassifier(hidden_layer_sizes=(1000,1000,1000), activation='tanh', solver='sgd',\n",
    "                    alpha=0.00000001,   batch_size= 10000,    learning_rate='adaptive',\n",
    "                    learning_rate_init=0.0001,    power_t=0.5,    max_iter=10000, \n",
    "                    shuffle=True,     random_state=None,  tol=0.00000001, \n",
    "                    verbose=True,     warm_start= True,   momentum=0.9, \n",
    "                    nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.5, \n",
    "                    beta_2=0.5, \n",
    "                    epsilon=1e-10\n",
    "                   )\n",
    "cnf.fit(training_examples, training_labels)\n",
    "sum(cnf.predict(training_examples) == training_labels)/len(training_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
