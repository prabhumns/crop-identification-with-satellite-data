{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('E:/Time Series/data_collect4.pkl','rb')\n",
    "dicti = pickle.load(file_object)\n",
    "file_object.close()\n",
    "data2=  dicti['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {key:value[:11000] for key, value in data.items() if len(value)>=11000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "for value in data.values():\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {key: [[np.uint16(i) for key2 in ['07','08','09','10','11','12'] for i in list(example[key2])] for example in value] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in ushort_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mins = {}; maxs = {}; means = {}\n",
    "for i in range(30):\n",
    "    lin = [l[i] for value in data.values() for l in value]\n",
    "    mins[i] = min(lin)\n",
    "    maxs[i] = max(lin)\n",
    "    means[i] = mean(lin)\n",
    "    \n",
    "data = {key: [[np.float64((example[i]-means[i])/(maxs[i] - mins[i])) for i in range(30)] for example in value] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "for key, value in data.items():\n",
    "    lit = []\n",
    "    for example in value:\n",
    "        lis = []\n",
    "        for key2 in ['07','08','09','10','11','12']:\n",
    "            value2 = list(example[key2])\n",
    "            for i in value2:\n",
    "                lis.append(np.uint16(i))\n",
    "        lit.append(lis)\n",
    "    print(len(lit))\n",
    "    data[key] = lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    lin = []\n",
    "    for key, value in data.items():\n",
    "        if key!= 'info':\n",
    "            for l in value:\n",
    "                lin.append(l[i])\n",
    "    mins = min(lin)\n",
    "    maxs = max(lin)\n",
    "    means = mean(lin)\n",
    "    for key, value in data.items():\n",
    "        for example in value:\n",
    "            example[i] = np.float64((example[i] - means)/(maxs-mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {key:[[example[i] for i in z] for example in value] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : SOYABEENS\n",
      "1 : CORN\n",
      "2 : DEVELOPED\n",
      "3 : FOREST\n",
      "4 : WATER BODY\n"
     ]
    }
   ],
   "source": [
    "training_examples = []\n",
    "training_labels = []\n",
    "test_examples = []\n",
    "test_labels = []\n",
    "cv_examples = []\n",
    "cv_labels = []\n",
    "i = 0;\n",
    "for key, value in data.items():\n",
    "    training_examples = training_examples + value[:9000]\n",
    "    cv_examples = cv_examples + value[9000:10000]\n",
    "    test_examples = test_examples + value[10000:]\n",
    "    training_labels = training_labels + [i for v in range(9000)]\n",
    "    cv_labels = cv_labels + [i for v in range(1000)]\n",
    "    test_labels = test_labels + [i for v in range(1000)]\n",
    "    print(i,':', key)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle as shf\n",
    "training_examples, training_labels  = shf(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06127524 0.01398746 0.02196455 0.11467601 0.01987551 0.03240372\n",
      " 0.02006415 0.07180373 0.02995107 0.0352105  0.01632578 0.0178532\n",
      " 0.03576882 0.03444795 0.02759525 0.02549255 0.01623841 0.04256522\n",
      " 0.02151836 0.07092703 0.02075564 0.01534277 0.03744998 0.03727137\n",
      " 0.03314784 0.02801742 0.02649667 0.04449899 0.01173838 0.0153364 ]\n",
      "3 ----- 0.11467601102590255\n",
      "7 ----- 0.07180373016884643\n",
      "19 ----- 0.0709270328113387\n",
      "0 ----- 0.06127524379411612\n",
      "27 ----- 0.04449899387502481\n",
      "17 ----- 0.04256522367409158\n",
      "22 ----- 0.037449983143291884\n",
      "23 ----- 0.03727136532711462\n",
      "12 ----- 0.035768820787592234\n",
      "9 ----- 0.03521050075938585\n",
      "13 ----- 0.03444795138216541\n",
      "24 ----- 0.033147844044021\n",
      "5 ----- 0.03240372051941482\n",
      "8 ----- 0.02995107222948054\n",
      "25 ----- 0.02801742069436499\n",
      "14 ----- 0.027595253359223665\n",
      "26 ----- 0.02649666785978133\n",
      "15 ----- 0.025492545292751245\n",
      "2 ----- 0.021964546403847762\n",
      "18 ----- 0.021518356637655424\n",
      "20 ----- 0.020755639418926105\n",
      "6 ----- 0.020064151217103116\n",
      "4 ----- 0.019875508082726995\n",
      "11 ----- 0.017853204386657034\n",
      "10 ----- 0.01632578418070286\n",
      "16 ----- 0.016238414212886843\n",
      "21 ----- 0.01534277136232847\n",
      "29 ----- 0.015336397914275665\n",
      "1 ----- 0.013987464412218546\n",
      "28 ----- 0.011738381022763342\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(training_examples + cv_examples, training_labels + cv_labels)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n",
    "s = model.feature_importances_\n",
    "L = np.array(s)\n",
    "t = sorted(range(len(L)), key=lambda i:L[i])\n",
    "z = []\n",
    "for j in t[::-1]:\n",
    "    print( j, '-----', s[j])\n",
    "    if s[j]>0.03: z.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(C = 100000.0, tol = 0.00001, verbose = True)\n",
    "clf.fit(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_object = open('clf.pkl', 'wb')\n",
    "pickle.dump(clf, file_object)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clf.predict(cv_examples) == cv_labels)/len(cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clf.predict(training_examples) == training_labels)/len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "cnf = MLPClassifier(alpha=1e-3,solver = 'sgd',\n",
    "\thidden_layer_sizes=(30,15,10,4), \n",
    "\tlearning_rate_init = 0.001, \n",
    "\tmax_iter = 1000, \n",
    "\tactivation = 'tanh',\n",
    "\tbatch_size = 100,\n",
    "\ttol = 0.000001,\n",
    "    verbose = True\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26807988\n",
      "Iteration 2, loss = 1.19372981\n",
      "Iteration 3, loss = 1.17899196\n",
      "Iteration 4, loss = 1.17156842\n",
      "Iteration 5, loss = 1.16493020\n",
      "Iteration 6, loss = 1.15802281\n",
      "Iteration 7, loss = 1.15362085\n",
      "Iteration 8, loss = 1.15142365\n",
      "Iteration 9, loss = 1.14988654\n",
      "Iteration 10, loss = 1.14879949\n",
      "Iteration 11, loss = 1.14786305\n",
      "Iteration 12, loss = 1.14689943\n",
      "Iteration 13, loss = 1.14631363\n",
      "Iteration 14, loss = 1.14583534\n",
      "Iteration 15, loss = 1.14492408\n",
      "Iteration 16, loss = 1.14472470\n",
      "Iteration 17, loss = 1.14384072\n",
      "Iteration 18, loss = 1.14288318\n",
      "Iteration 19, loss = 1.14243831\n",
      "Iteration 20, loss = 1.14084054\n",
      "Iteration 21, loss = 1.13933805\n",
      "Iteration 22, loss = 1.13718415\n",
      "Iteration 23, loss = 1.13477061\n",
      "Iteration 24, loss = 1.13107668\n",
      "Iteration 25, loss = 1.12712950\n",
      "Iteration 26, loss = 1.12117981\n",
      "Iteration 27, loss = 1.11405898\n",
      "Iteration 28, loss = 1.10647516\n",
      "Iteration 29, loss = 1.09826025\n",
      "Iteration 30, loss = 1.09033091\n",
      "Iteration 31, loss = 1.08165387\n",
      "Iteration 32, loss = 1.07266768\n",
      "Iteration 33, loss = 1.06510644\n",
      "Iteration 34, loss = 1.05794363\n",
      "Iteration 35, loss = 1.05141233\n",
      "Iteration 36, loss = 1.04658751\n",
      "Iteration 37, loss = 1.04027497\n",
      "Iteration 38, loss = 1.03558891\n",
      "Iteration 39, loss = 1.03139071\n",
      "Iteration 40, loss = 1.02614498\n",
      "Iteration 41, loss = 1.02365749\n",
      "Iteration 42, loss = 1.02063648\n",
      "Iteration 43, loss = 1.01699435\n",
      "Iteration 44, loss = 1.01326379\n",
      "Iteration 45, loss = 1.01002396\n",
      "Iteration 46, loss = 1.00713563\n",
      "Iteration 47, loss = 1.00561830\n",
      "Iteration 48, loss = 1.00154010\n",
      "Iteration 49, loss = 0.99938737\n",
      "Iteration 50, loss = 0.99588798\n",
      "Iteration 51, loss = 0.99362419\n",
      "Iteration 52, loss = 0.98996663\n",
      "Iteration 53, loss = 0.98710424\n",
      "Iteration 54, loss = 0.98490902\n",
      "Iteration 55, loss = 0.98273820\n",
      "Iteration 56, loss = 0.98007051\n",
      "Iteration 57, loss = 0.97878383\n",
      "Iteration 58, loss = 0.97448023\n",
      "Iteration 59, loss = 0.97346406\n",
      "Iteration 60, loss = 0.97157130\n",
      "Iteration 61, loss = 0.96885483\n",
      "Iteration 62, loss = 0.96809910\n",
      "Iteration 63, loss = 0.96718307\n",
      "Iteration 64, loss = 0.96470682\n",
      "Iteration 65, loss = 0.96247515\n",
      "Iteration 66, loss = 0.96195002\n",
      "Iteration 67, loss = 0.96027887\n",
      "Iteration 68, loss = 0.96372780\n",
      "Iteration 69, loss = 0.95725194\n",
      "Iteration 70, loss = 0.95601560\n",
      "Iteration 71, loss = 0.95283231\n",
      "Iteration 72, loss = 0.95188263\n",
      "Iteration 73, loss = 0.95112509\n",
      "Iteration 74, loss = 0.95018555\n",
      "Iteration 75, loss = 0.94691351\n",
      "Iteration 76, loss = 0.94691356\n",
      "Iteration 77, loss = 0.95795033\n",
      "Iteration 78, loss = 0.94456941\n",
      "Iteration 79, loss = 0.95258430\n",
      "Iteration 80, loss = 0.94708843\n",
      "Iteration 81, loss = 0.94395302\n",
      "Iteration 82, loss = 0.93722594\n",
      "Iteration 83, loss = 0.93590642\n",
      "Iteration 84, loss = 0.94210386\n",
      "Iteration 85, loss = 0.94749164\n",
      "Iteration 86, loss = 0.94279874\n",
      "Training loss did not improve more than tol=0.000001 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.001, batch_size=100, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 15, 10, 4), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf.fit(training_examples, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58975"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cnf.predict(cv_examples) == cv_labels)/len(cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6173055555555556"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cnf.predict(training_examples) == training_labels)/len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
